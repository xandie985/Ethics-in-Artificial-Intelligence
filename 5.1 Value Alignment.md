# Value Alignment (VA)
### Intelligence
- no universal definition. 
- ability to adapt to new scenarios. 

### AI
- is the simulation of human intelligence processes by machines, especially computer systems. 
- Specific applications of AI include expert systems, natural language processing, speech recognition and machine vision.
- Narrow AI
  - ability to perform specific task
- General AI
  - ability to perform general taks. 

### VA problem
- AI should be made more benefitial for society, not just mere progress. 
-  should be interdiscplinary research (psychology, maths, teaching, etc.)

* Optimizing AI impact on economy
  * labour mrket disruption
  * policy management for adverse effects 
* Law and ethics research
  * Liability of Law and AV
  * Machine Ethics
  * A Vehicles 
* CS research for robust AI
  * Verificatoin
  * Validity
  * Security
  * Control

Value alignment: ensures values are embedded in the choices made by AI.

### What are values, norms and principles? (V,N,P)
![image](https://user-images.githubusercontent.com/18325219/173237201-8aec4b55-fee9-4187-b3c3-ee1ee415f045.png)

V
- can be grounded to simple valence - -like/dislike  
- an individual's accepted standards of right or wrong.
- can be intrinsic or unconditional
- extrisic or conditional

N
- standardized ways of conduct and behavior (e.g., treating everyone fairly) in a society, company, or other organization.
- AI sys can be taught norms but how deep we have to teach them
  - Top down approach
  - Bottom up approach
  ![image](https://user-images.githubusercontent.com/18325219/173237315-8c6fdd94-d097-47f3-b5d1-797bae795745.png)
  ![image](https://user-images.githubusercontent.com/18325219/173237347-5f75a868-3d4d-4246-b123-73235eb0eec0.png)

### AI limits
- NLP comprehension is poor
- reasoning is poor
- learning from few samples (Bottom top approach)
- Abstraction is poort
- Ethical limitation - bias/blackbox and adversial attack

### AI & Bias
Chatbot tay: racist/hitler was good person. 
Google sentiment analyzer: being gay is bad. 

GAN:
![image](https://user-images.githubusercontent.com/18325219/173237856-5849dcd2-25f6-4570-8299-9afe9ca7bc17.png)

Adversial Attack: 
An adversarial example is an input (e.g. image, sound) designed to cause a machine learning model to make a wrong prediction. It is generated from a clean example by adding a small perturbation, imperceptible for humans, but sensitive enough for the model to change its prediction.  

Some application:
How to constraint AI systems to avoid issued above?
- here system learns the weights used by the people on which they judge the situation:
  - notion of distance between CP nets
  - metric learning for value alignment
- way human decide how they decide - how people switch from one way to other form of thinkning
  - when is it morally acceptable to break rule?
- this combines the preferences of individuals and Autonomous decision making systems from AV to understand how to 
  - Genetic approach to ethical knob 

![image](https://user-images.githubusercontent.com/18325219/173240021-41907c8c-0a5c-483c-86b5-2a64fea1e7bc.png)

### Reward hacking
- bots teaching themselves to cheat
- constantly hitting the powe up instead of playing game. 
- Challences in AI Satety: 
  - Safe exploration
  - avoid -ve side effects

### Ethically bounded AI: Value alignment & Machine ethics
![image](https://user-images.githubusercontent.com/18325219/173240239-f19fceee-b65d-4118-b182-6255729f9fc4.png)

### Preferences in Constraint Satisfaction
* CP-nets: these represent the graphical peresentation of preferences. 
* CP net presents conoditinal preferences. 
![image](https://user-images.githubusercontent.com/18325219/173240471-34d5eebe-5fa8-489f-ae68-c7fe70f93f77.png)

Distance between discrete sttructures: represent how favourable the items are as compared to others.
*To understand whether 2 agents agree/disagree*
We need to compare how similar 2 CP nets are - measured with *Kendall Tau*

![image](https://user-images.githubusercontent.com/18325219/173241166-359803e1-05c0-4724-a376-685987102d51.png)

